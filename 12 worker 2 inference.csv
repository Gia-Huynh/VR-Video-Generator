Function,Line #,Line Content,Hits,Total Time (µs),Per Hit (µs)
inference_worker_backup,87,"    redirrect_stdout(DebugDir + f""inference_worker_{os.getpid()}.txt"")",1,1569,1569.00
inference_worker_backup,88,"    print_flush (encoder, encoder_path, DEVICE)",1,938,938.00
inference_worker_backup,89,"    print_flush (""Torch model loading into device name: "", torch.cuda.get_device_name(DEVICE))",1,958,958.00
inference_worker_backup,90,"    model = load_model(encoder, encoder_path, DEVICE)",1,6421533,6421533.00
inference_worker_backup,91,"    print_flush (""Model loaded, trying to infer an image..."")",1,583,583.00
inference_worker_backup,92,"    model.infer_image (np.zeros((1080, 1920, 3), dtype = np.uint8))",1,3897382,3897382.00
inference_worker_backup,93,    torch.cuda.empty_cache(),1,80209,80209.00
inference_worker_backup,94,"    print_flush (""Model loaded"")",1,752,752.00
inference_worker_backup,95,    while True:,457,2795,6.12
inference_worker_backup,96,        queue_idx = notify_queue_list.get(),457,56364867,123336.69
inference_worker_backup,97,        if queue_idx is None:,457,2507,5.49
inference_worker_backup,98,            break,1,4,4.00
inference_worker_backup,99,        task = in_queue_list[queue_idx[0]].get(),456,27135708,59508.13
inference_worker_backup,100,        if task is None:,456,4356,9.55
inference_worker_backup,102,        img = task[0],456,953576,2091.18
inference_worker_backup,103,"        with torch.no_grad(), autocast(device_type=DEVICE.type, dtype=torch.float16):",912,1691640,1854.87
inference_worker_backup,104,            result = model.infer_image_gpu(img),456,543726378,1192382.41
inference_worker_backup,105,        out_queue_list[queue_idx[0]].put(result),456,275752,604.72
